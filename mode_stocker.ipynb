{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHKR5OfInokO"
      },
      "outputs": [],
      "source": [
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\" -q\n",
        "!pip install yfinance pandas numpy matplotlib seaborn scikit-learn -q\n",
        "!pip install --upgrade transformers datasets accelerate bitsandbytes -q\n",
        "\n",
        "# Tech Analysis library\n",
        "!wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz -q\n",
        "!tar -xzf ta-lib-0.4.0-src.tar.gz\n",
        "!cd ta-lib && ./configure --prefix=/usr && make && make install\n",
        "!pip install TA-Lib -q\n",
        "\n",
        "print(\"✅ Installation complete! Please RESTART RUNTIME now!\")\n",
        "print(\"After restart, run the next cell...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8I1zl9gn5dR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import json\n",
        "from datetime import datetime, timedelta\n",
        "from typing import List, Dict, Any\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# unsloth imports\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "# Custom TA Funx\n",
        "class TechnicalIndicators:\n",
        "    @staticmethod\n",
        "    def rsi(prices, period=14):\n",
        "        \"\"\"Calculate RSI\"\"\"\n",
        "        delta = prices.diff()\n",
        "        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
        "        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
        "        rs = gain / loss\n",
        "        return 100 - (100 / (1 + rs))\n",
        "\n",
        "    @staticmethod\n",
        "    def macd(prices, fast=12, slow=26, signal=9):\n",
        "        \"\"\"Calculate MACD\"\"\"\n",
        "        ema_fast = prices.ewm(span=fast).mean()\n",
        "        ema_slow = prices.ewm(span=slow).mean()\n",
        "        macd_line = ema_fast - ema_slow\n",
        "        signal_line = macd_line.ewm(span=signal).mean()\n",
        "        return macd_line, signal_line\n",
        "\n",
        "    @staticmethod\n",
        "    def sma(prices, period):\n",
        "        \"\"\"Simple Moving Average\"\"\"\n",
        "        return prices.rolling(window=period).mean()\n",
        "\n",
        "print(\"🚀 Imports successful! Starting trading model setup...\")\n",
        "\n",
        "class StockDataProcessor:\n",
        "    \"\"\"Processes stock data and creates training dataset\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # High-risk, high-reward stock tickers\n",
        "        self.high_risk_tickers = [\n",
        "            'TSLA', 'NVDA', 'AMD', 'PLTR', 'MSTR', 'COIN',\n",
        "            'MRNA', 'BNTX', 'GME', 'AMC', 'SPCE', 'MARA',\n",
        "            'RIOT', 'BABA', 'NIO'  # Reduced list for faster processing\n",
        "        ]\n",
        "\n",
        "    def fetch_stock_data(self, ticker: str, period: str = '1y') -> pd.DataFrame:\n",
        "        \"\"\"Fetch comprehensive stock data\"\"\"\n",
        "        try:\n",
        "            print(f\"  📈 Fetching {ticker}...\")\n",
        "            stock = yf.Ticker(ticker)\n",
        "            df = stock.history(period=period)\n",
        "\n",
        "            if df.empty:\n",
        "                return None\n",
        "\n",
        "            # Custom technical indicators (no TA-Lib needed!)\n",
        "            ta = TechnicalIndicators()\n",
        "\n",
        "            df['RSI'] = ta.rsi(df['Close'])\n",
        "            df['MACD'], df['MACD_signal'] = ta.macd(df['Close'])\n",
        "            df['SMA_20'] = ta.sma(df['Close'], 20)\n",
        "            df['SMA_50'] = ta.sma(df['Close'], 50)\n",
        "\n",
        "            # Price changes and volatility\n",
        "            df['Price_Change'] = df['Close'].pct_change()\n",
        "            df['Volatility'] = df['Price_Change'].rolling(window=20).std()\n",
        "            df['Volume_MA'] = df['Volume'].rolling(window=20).mean()\n",
        "            df['Volume_Ratio'] = df['Volume'] / df['Volume_MA']\n",
        "\n",
        "            # Future returns (target variable)\n",
        "            df['Future_1d'] = df['Close'].shift(-1) / df['Close'] - 1\n",
        "            df['Future_5d'] = df['Close'].shift(-5) / df['Close'] - 1\n",
        "\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ❌ Error fetching {ticker}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def create_training_prompt(self, row: pd.Series, ticker: str) -> Dict[str, str]:\n",
        "        \"\"\"Create training prompt from stock data\"\"\"\n",
        "\n",
        "        current_price = row['Close']\n",
        "        rsi = row['RSI']\n",
        "        macd = row['MACD']\n",
        "        volume_ratio = row['Volume_Ratio']\n",
        "        volatility = row['Volatility'] * 100\n",
        "\n",
        "        # Technical signals\n",
        "        signals = []\n",
        "        if rsi < 30:\n",
        "            signals.append(\"oversold\")\n",
        "        elif rsi > 70:\n",
        "            signals.append(\"overbought\")\n",
        "\n",
        "        if macd > row['MACD_signal']:\n",
        "            signals.append(\"bullish MACD\")\n",
        "        else:\n",
        "            signals.append(\"bearish MACD\")\n",
        "\n",
        "        # Determine action based on future returns\n",
        "        future_1d = row['Future_1d']\n",
        "\n",
        "        if pd.isna(future_1d):\n",
        "            return None\n",
        "\n",
        "        if future_1d > 0.03:\n",
        "            action = \"STRONG BUY\"\n",
        "        elif future_1d > 0.01:\n",
        "            action = \"BUY\"\n",
        "        elif future_1d < -0.03:\n",
        "            action = \"STRONG SELL\"\n",
        "        elif future_1d < -0.01:\n",
        "            action = \"SELL\"\n",
        "        else:\n",
        "            action = \"HOLD\"\n",
        "\n",
        "        prompt = f\"\"\"Analyze this high-risk stock:\n",
        "Stock: {ticker}\n",
        "Price: ${current_price:.2f}\n",
        "RSI: {rsi:.1f}\n",
        "MACD: {macd:.4f}\n",
        "Volume: {volume_ratio:.2f}x normal\n",
        "Volatility: {volatility:.2f}%\n",
        "Signals: {', '.join(signals)}\n",
        "\n",
        "Provide trading recommendation:\"\"\"\n",
        "\n",
        "        response = f\"\"\"RECOMMENDATION: {action}\n",
        "REASONING: {ticker} shows {', '.join(signals)} with {volatility:.2f}% volatility.\n",
        "TARGET: {future_1d*100:+.2f}% expected 1-day move.\n",
        "RISK: {'HIGH' if volatility > 3 else 'MEDIUM'} - use small position size.\"\"\"\n",
        "\n",
        "        return {\n",
        "            \"instruction\": prompt,\n",
        "            \"output\": response\n",
        "        }\n",
        "\n",
        "def prepare_training_data(max_samples: int = 1000) -> Dataset:\n",
        "    \"\"\"Prepare training dataset\"\"\"\n",
        "    print(\"📊 Preparing training data...\")\n",
        "    processor = StockDataProcessor()\n",
        "    training_data = []\n",
        "\n",
        "    for ticker in processor.high_risk_tickers:\n",
        "        df = processor.fetch_stock_data(ticker)\n",
        "\n",
        "        if df is None or df.empty:\n",
        "            continue\n",
        "\n",
        "        # Sample data points\n",
        "        sample_size = min(50, len(df.dropna()))  # 50 samples per stock\n",
        "        sampled_df = df.dropna().tail(sample_size)  # Use recent data\n",
        "\n",
        "        for idx, row in sampled_df.iterrows():\n",
        "            prompt_data = processor.create_training_prompt(row, ticker)\n",
        "            if prompt_data:\n",
        "                formatted_prompt = f\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "{prompt_data['instruction']}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\n",
        "{prompt_data['output']}<|eot_id|>\"\"\"\n",
        "\n",
        "                training_data.append({\"text\": formatted_prompt})\n",
        "\n",
        "    print(f\"✅ Created {len(training_data)} training samples\")\n",
        "    return Dataset.from_list(training_data)\n",
        "\n",
        "def setup_and_train_model():\n",
        "    \"\"\"Setup and train the model\"\"\"\n",
        "    print(\"🤖 Loading model...\")\n",
        "\n",
        "    # Load model\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name = \"unsloth/llama-3.1-8b-instruct-bnb-4bit\",\n",
        "        max_seq_length = 2048,\n",
        "        dtype = None,\n",
        "        load_in_4bit = True,\n",
        "    )\n",
        "\n",
        "    # Setup LoRA\n",
        "    model = FastLanguageModel.get_peft_model(\n",
        "        model,\n",
        "        r = 16,\n",
        "        target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                          \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "        lora_alpha = 16,\n",
        "        lora_dropout = 0,\n",
        "        bias = \"none\",\n",
        "        use_gradient_checkpointing = \"unsloth\",\n",
        "        random_state = 3407,\n",
        "    )\n",
        "\n",
        "    print(\"📚 Preparing training data...\")\n",
        "    dataset = prepare_training_data()\n",
        "\n",
        "    print(\"🏋️ Starting training...\")\n",
        "    trainer = SFTTrainer(\n",
        "        model = model,\n",
        "        tokenizer = tokenizer,\n",
        "        train_dataset = dataset,\n",
        "        dataset_text_field = \"text\",\n",
        "        max_seq_length = 2048,\n",
        "        dataset_num_proc = 1,\n",
        "        packing = False,\n",
        "        args = TrainingArguments(\n",
        "            per_device_train_batch_size = 1,  # Small batch for Colab\n",
        "            gradient_accumulation_steps = 8,\n",
        "            warmup_steps = 10,\n",
        "            max_steps = 50,  # Quick training\n",
        "            learning_rate = 2e-4,\n",
        "            fp16 = not is_bfloat16_supported(),\n",
        "            bf16 = is_bfloat16_supported(),\n",
        "            logging_steps = 5,\n",
        "            optim = \"adamw_8bit\",\n",
        "            weight_decay = 0.01,\n",
        "            lr_scheduler_type = \"linear\",\n",
        "            seed = 3407,\n",
        "            output_dir = \"outputs\",\n",
        "            dataloader_pin_memory = False,\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    print(\"💾 Saving model...\")\n",
        "    model.save_pretrained(\"trading_model\")\n",
        "    tokenizer.save_pretrained(\"trading_model\")\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "def test_model(model, tokenizer):\n",
        "    \"\"\"Test the trained model\"\"\"\n",
        "    print(\"\\n🧪 Testing model...\")\n",
        "\n",
        "    test_prompt = \"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "Analyze this high-risk stock:\n",
        "Stock: TSLA\n",
        "Price: $242.50\n",
        "RSI: 45.2\n",
        "MACD: 1.23\n",
        "Volume: 1.8x normal\n",
        "Volatility: 4.2%\n",
        "Signals: neutral RSI, bullish MACD\n",
        "\n",
        "Provide trading recommendation:<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens = 256,\n",
        "            temperature = 0.7,\n",
        "            do_sample = True,\n",
        "            pad_token_id = tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    print(\"📊 Sample Analysis:\")\n",
        "    print(response.split(\"<|start_header_id|>assistant<|end_header_id|>\")[-1])\n",
        "\n",
        "# Main execution\n",
        "print(\"🎯 Starting High-Risk Trading Model Training\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "try:\n",
        "    model, tokenizer = setup_and_train_model()\n",
        "    test_model(model, tokenizer)\n",
        "    print(\"\\n✅ Training Complete!\")\n",
        "    print(\"🚀 Model ready for trading analysis!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error: {e}\")\n",
        "    print(\"💡 Make sure you restarted runtime after installation!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOi1ZF3aoCye"
      },
      "outputs": [],
      "source": [
        "def analyze_live_stock(ticker: str):\n",
        "    \"\"\"Analyze a stock in real-time using custom technical indicators\"\"\"\n",
        "    try:\n",
        "        from unsloth import FastLanguageModel\n",
        "        import yfinance as yf\n",
        "        import torch\n",
        "\n",
        "        # Load the trained model\n",
        "        model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "            \"trading_model\",\n",
        "            max_seq_length=2048,\n",
        "            dtype=None,\n",
        "            load_in_4bit=True,\n",
        "        )\n",
        "\n",
        "        # Get fresh data\n",
        "        stock = yf.Ticker(ticker)\n",
        "        df = stock.history(period='30d')\n",
        "        if df.empty:\n",
        "            print(f\"❌ No data found for {ticker}\")\n",
        "            return\n",
        "\n",
        "        latest = df.iloc[-1]\n",
        "\n",
        "        # Calculate indicators using your class\n",
        "        ta = TechnicalIndicators()\n",
        "        rsi = ta.rsi(df['Close']).iloc[-1]\n",
        "        macd_line, macd_signal = ta.macd(df['Close'])\n",
        "        macd = macd_line.iloc[-1]\n",
        "        macd_sig = macd_signal.iloc[-1]\n",
        "\n",
        "        prompt = f\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "Analyze this high-risk stock:\n",
        "Stock: {ticker}\n",
        "Price: ${latest['Close']:.2f}\n",
        "RSI: {rsi:.1f}\n",
        "MACD: {macd:.2f}\n",
        "Volume: {latest['Volume']:.0f}\n",
        "\n",
        "Provide trading recommendation:<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "        model = model.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=200,\n",
        "                temperature=0.7,\n",
        "                do_sample=True,\n",
        "                pad_token_id=tokenizer.eos_token_id,\n",
        "            )\n",
        "\n",
        "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        analysis = response.split(\"<|start_header_id|>assistant<|end_header_id|>\")[-1]\n",
        "\n",
        "        print(f\"\\n📊 Live Analysis for {ticker}:\")\n",
        "        print(\"=\" * 30)\n",
        "        print(analysis)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error analyzing {ticker}: {e}\")\n",
        "\n",
        "# RUN IT!!!\n",
        "analyze_live_stock(\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBiCjw9dwBR1"
      },
      "outputs": [],
      "source": [
        "analyze_live_stock(\"BSGM\")\n",
        "analyze_live_stock(\"SCPH\")\n",
        "analyze_live_stock(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xxR7AMj3usqW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "authorship_tag": "ABX9TyM/hhm/H8r9+HsMpzFrq6aM"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}